#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
–û–±–Ω–æ–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ –∏–∑–º–µ–Ω—ë–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã—Ö —Å—É–º–º
"""

import os
import sys
import hashlib
import re
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Tuple, Set

try:
    import PyPDF2
except ImportError:
    print("–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫...")
    os.system(f"{sys.executable} -m pip install PyPDF2 --quiet")
    import PyPDF2


class KnowledgeBaseUpdater:
    def __init__(self, raw_dir: str, knowledge_dir: str):
        self.raw_dir = Path(raw_dir)
        self.knowledge_dir = Path(knowledge_dir)
        self.update_date = datetime.now().strftime("%Y-%m-%d")
        self.update_log = []
        self.updated_count = 0
        self.skipped_count = 0
        self.new_count = 0
        self.documents = []
        
    def log(self, message: str):
        """–î–æ–±–∞–≤–∏—Ç—å –∑–∞–ø–∏—Å—å –≤ –ª–æ–≥"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        log_entry = f"[{timestamp}] {message}"
        self.update_log.append(log_entry)
        print(log_entry)
    
    def calculate_checksum(self, file_path: Path) -> str:
        """–í—ã—á–∏—Å–ª–∏—Ç—å SHA256 —Ö–µ—à —Ñ–∞–π–ª–∞ (–ø–µ—Ä–≤—ã–µ 16 —Å–∏–º–≤–æ–ª–æ–≤)"""
        sha256 = hashlib.sha256()
        with open(file_path, 'rb') as f:
            for chunk in iter(lambda: f.read(8192), b""):
                sha256.update(chunk)
        return sha256.hexdigest()[:16]
    
    def extract_metadata_from_md(self, md_path: Path) -> Dict:
        """–ò–∑–≤–ª–µ—á—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ Markdown —Ñ–∞–π–ª–∞"""
        try:
            with open(md_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # –ò—â–µ–º YAML frontmatter
            match = re.match(r'^---\s*\n(.*?)\n---', content, re.DOTALL)
            if not match:
                return {}
            
            yaml_content = match.group(1)
            
            # –ü–∞—Ä—Å–∏–º YAML –≤—Ä—É—á–Ω—É—é (–ø—Ä–æ—Å—Ç–æ–π –ø–∞—Ä—Å–µ—Ä)
            metadata = {}
            for line in yaml_content.split('\n'):
                if ':' in line and not line.strip().startswith('-'):
                    key, value = line.split(':', 1)
                    key = key.strip()
                    value = value.strip().strip('"\'')
                    metadata[key] = value
            
            return metadata
        except Exception as e:
            self.log(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–∑ {md_path.name}: {e}")
            return {}
    
    def find_md_for_source(self, source_filename: str) -> List[Path]:
        """–ù–∞–π—Ç–∏ –≤—Å–µ MD —Ñ–∞–π–ª—ã, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –∏—Å—Ö–æ–¥–Ω—ã–º —Ñ–∞–π–ª–æ–º"""
        md_files = []
        
        if not self.knowledge_dir.exists():
            return md_files
        
        # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –∏—â–µ–º –≤—Å–µ .md —Ñ–∞–π–ª—ã
        for md_file in self.knowledge_dir.rglob("*.md"):
            if md_file.name in ['00_index.md', 'build_log.md', 'update_log.md']:
                continue
            
            try:
                with open(md_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if f'raw/{source_filename}' in content:
                        md_files.append(md_file)
            except:
                continue
        
        return md_files
    
    def extract_text_from_pdf(self, pdf_path: Path) -> Tuple[str, int]:
        """–ò–∑–≤–ª–µ—á—å –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∏–∑ PDF —Ñ–∞–π–ª–∞"""
        text_content = []
        page_count = 0
        
        try:
            with open(pdf_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                page_count = len(pdf_reader.pages)
                
                for page_num, page in enumerate(pdf_reader.pages, 1):
                    page_text = page.extract_text()
                    if page_text.strip():
                        text_content.append(f"--- –°–ª–∞–π–¥ {page_num} ---")
                        text_content.append(page_text.strip())
                        text_content.append("")
                        
        except Exception as e:
            self.log(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ {pdf_path.name}: {e}")
            return "", 0
        
        return "\n".join(text_content), page_count
    
    def categorize_file(self, filename: str, content: str) -> Dict[str, any]:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É"""
        filename_lower = filename.lower()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç—Ä–∞–Ω—É/—Ä–µ–≥–∏–æ–Ω –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        match = re.match(r'Intermark\.\s+(.+?)\s+(Residence|Citizenship|Passport|visa|RP|PR|Permit)', 
                        filename, re.IGNORECASE)
        
        if match:
            country = match.group(1).strip()
        else:
            parts = filename.replace("Intermark.", "").replace("ENG.pdf", "").strip().split(".")
            country = parts[0].strip() if parts else "–û–±—â–µ–µ"
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø—Ä–æ–≥—Ä–∞–º–º—ã
        if any(word in filename_lower for word in ['citizenship', '–≥—Ä–∞–∂–¥–∞–Ω—Å—Ç–≤–æ']):
            program_type = '–ì—Ä–∞–∂–¥–∞–Ω—Å—Ç–≤–æ'
            subcategory = 'citizenship'
        elif any(word in filename_lower for word in ['permanent residence', 'pr']):
            program_type = '–ü–æ—Å—Ç–æ—è–Ω–Ω–æ–µ –ø—Ä–æ–∂–∏–≤–∞–Ω–∏–µ'
            subcategory = 'permanent-residence'
        elif any(word in filename_lower for word in ['residence permit', 'rp', 'visa']):
            program_type = '–í–∏–¥ –Ω–∞ –∂–∏—Ç–µ–ª—å—Å—Ç–≤–æ'
            subcategory = 'residence-permit'
        elif 'passport' in filename_lower:
            program_type = '–ü–∞—Å–ø–æ—Ä—Ç'
            subcategory = 'passport'
        elif 'golden visa' in filename_lower:
            program_type = '–ó–æ–ª–æ—Ç–∞—è –≤–∏–∑–∞'
            subcategory = 'golden-visa'
        else:
            program_type = '–û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è'
            subcategory = 'general'
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
        lines = [l.strip() for l in content.split('\n') if l.strip() and not l.startswith('---')]
        summary = ' '.join(lines[:3])[:200] if lines else "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∏–º–º–∏–≥—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º–µ"
        
        # –¢–µ–≥–∏
        tags = [country, program_type]
        if 'investment' in filename_lower or 'invest' in content.lower()[:500]:
            tags.append('–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏')
        if 'startup' in filename_lower:
            tags.append('—Å—Ç–∞—Ä—Ç–∞–ø')
        if 'digital nomad' in filename_lower:
            tags.append('digital-nomad')
        if 'financial independence' in filename_lower:
            tags.append('—Ñ–∏–Ω–∞–Ω—Å–æ–≤–∞—è-–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å')
        
        return {
            'country': country,
            'program_type': program_type,
            'subcategory': subcategory,
            'summary': summary,
            'tags': tags
        }
    
    def create_markdown_document(self, pdf_file: Path, text: str, page_count: int, 
                                 metadata: Dict) -> Tuple[str, str]:
        """–°–æ–∑–¥–∞—Ç—å Markdown –¥–æ–∫—É–º–µ–Ω—Ç –ø–æ —à–∞–±–ª–æ–Ω—É"""
        checksum = self.calculate_checksum(pdf_file)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞
        safe_name = re.sub(r'[^\w\s-]', '', metadata['country'])
        safe_name = re.sub(r'[-\s]+', '-', safe_name).strip('-').lower()
        md_filename = f"{safe_name}-{metadata['subcategory']}.md"
        
        # –°–æ–∑–¥–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç
        doc = f"""---
title: "{metadata['country']}: {metadata['program_type']}"
summary: "{metadata['summary']}"
category: "{metadata['country']}"
subcategory: "{metadata['subcategory']}"
tags: {metadata['tags']}
source_files:
  - path: "raw/{pdf_file.name}"
    slides: [1-{page_count}]
extraction_date: "{self.update_date}"
version: "{checksum}"
checksum_sources: "{checksum}"
doc_type: "knowledge"
related: []
---

# {metadata['country']}: {metadata['program_type']}

## –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏

{text}

---

### –ò—Å—Ç–æ—á–Ω–∏–∫–∏
[^src1]: raw/{pdf_file.name} ‚Üí —Å–ª–∞–π–¥—ã 1‚Äì{page_count}
"""
        
        return md_filename, doc
    
    def update_files(self):
        """–û–±–Ω–æ–≤–∏—Ç—å –∏–∑–º–µ–Ω—ë–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã"""
        pdf_files = sorted(self.raw_dir.glob("*.pdf"))
        
        if not pdf_files:
            self.log("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ PDF —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ raw/")
            return {}
        
        self.log(f"üìö –ù–∞–π–¥–µ–Ω–æ {len(pdf_files)} PDF —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")
        
        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Å—Ç—Ä–∞–Ω–∞–º
        countries = {}
        
        for i, pdf_file in enumerate(pdf_files, 1):
            self.log(f"üìÑ [{i}/{len(pdf_files)}] –ü—Ä–æ–≤–µ—Ä–∫–∞: {pdf_file.name}")
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Ç–µ–∫—É—â–∏–π —Ö–µ—à
            current_checksum = self.calculate_checksum(pdf_file)
            
            # –ò—â–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ MD —Ñ–∞–π–ª—ã
            md_files = self.find_md_for_source(pdf_file.name)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –æ–±–Ω–æ–≤–ª—è—Ç—å
            needs_update = False
            existing_md = None
            
            if not md_files:
                self.log(f"  ‚ûï –ù–æ–≤—ã–π —Ñ–∞–π–ª (–Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ)")
                needs_update = True
                self.new_count += 1
            else:
                existing_md = md_files[0]
                metadata = self.extract_metadata_from_md(existing_md)
                stored_checksum = metadata.get('checksum_sources', '')
                
                if stored_checksum != current_checksum:
                    self.log(f"  üîÑ –§–∞–π–ª –∏–∑–º–µ–Ω—ë–Ω (—Ö–µ—à: {stored_checksum[:8]} ‚Üí {current_checksum[:8]})")
                    needs_update = True
                    self.updated_count += 1
                else:
                    self.log(f"  ‚úÖ –ë–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π")
                    self.skipped_count += 1
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞
                    doc_info = {
                        'country': metadata.get('category', 'Unknown'),
                        'title': metadata.get('title', pdf_file.stem),
                        'path': str(existing_md.relative_to(self.knowledge_dir)),
                        'summary': metadata.get('summary', ''),
                        'subcategory': metadata.get('subcategory', 'general'),
                        'tags': []
                    }
                    self.documents.append(doc_info)
                    
                    if doc_info['country'] not in countries:
                        countries[doc_info['country']] = []
                    countries[doc_info['country']].append(doc_info)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–∞–π–ª –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if needs_update:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
                text, page_count = self.extract_text_from_pdf(pdf_file)
                
                if not text:
                    self.log(f"  ‚ö†Ô∏è  –ü—Ä–æ–ø—É—Å–∫: –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç")
                    continue
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é
                file_metadata = self.categorize_file(pdf_file.name, text)
                
                # –°–æ–∑–¥–∞–µ–º markdown
                md_filename, md_content = self.create_markdown_document(
                    pdf_file, text, page_count, file_metadata
                )
                
                # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Å—Ç—Ä–∞–Ω—ã
                country_dir = self.knowledge_dir / file_metadata['country']
                country_dir.mkdir(exist_ok=True)
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
                if existing_md:
                    md_path = existing_md
                else:
                    md_path = country_dir / md_filename
                    version = 2
                    while md_path.exists():
                        base_name = md_filename.replace('.md', '')
                        md_filename = f"{base_name}_v{version}.md"
                        md_path = country_dir / md_filename
                        version += 1
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º
                with open(md_path, 'w', encoding='utf-8') as f:
                    f.write(md_content)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
                doc_info = {
                    'country': file_metadata['country'],
                    'title': f"{file_metadata['country']}: {file_metadata['program_type']}",
                    'path': str(md_path.relative_to(self.knowledge_dir)),
                    'summary': file_metadata['summary'],
                    'subcategory': file_metadata['subcategory'],
                    'tags': file_metadata['tags']
                }
                self.documents.append(doc_info)
                
                if file_metadata['country'] not in countries:
                    countries[file_metadata['country']] = []
                countries[file_metadata['country']].append(doc_info)
                
                self.log(f"  ‚úÖ –û–±–Ω–æ–≤–ª—ë–Ω: {md_path.relative_to(self.knowledge_dir)}")
        
        return countries
    
    def create_index(self, countries: Dict):
        """–û–±–Ω–æ–≤–∏—Ç—å –∏–Ω–¥–µ–∫—Å–Ω—ã–π —Ñ–∞–π–ª 00_index.md"""
        self.log("üìë –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞...")
        
        index_content = f"""---
title: "–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π ‚Äî –ò–º–º–∏–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã"
type: "index"
created: "{self.update_date}"
total_documents: {len(self.documents)}
total_categories: {len(countries)}
version: "{hashlib.md5(str(self.documents).encode()).hexdigest()[:8]}"
---

# –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π ‚Äî –ò–º–º–∏–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã

–ü–æ–ª–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏–º–º–∏–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö –ø—Ä–æ–≥—Ä–∞–º–º Intermark Global.

**–û–±–Ω–æ–≤–ª–µ–Ω–æ:** {self.update_date}  
**–í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:** {len(self.documents)}  
**–ö–∞—Ç–µ–≥–æ—Ä–∏–π (—Å—Ç—Ä–∞–Ω/—Ä–µ–≥–∏–æ–Ω–æ–≤):** {len(countries)}

---

## –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ —Å—Ç—Ä–∞–Ω–∞–º

"""
        
        for country in sorted(countries.keys()):
            docs = countries[country]
            index_content += f"\n### {country}\n\n"
            
            for doc in sorted(docs, key=lambda x: x['subcategory']):
                index_content += f"- [{doc['title']}]({doc['path']})\n"
                summary_text = doc['summary'][:100] + "..." if len(doc['summary']) > 100 else doc['summary']
                index_content += f"  - *{summary_text}*\n"
        
        index_content += f"""

---

## –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞

- –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(self.documents)}
- –ö–∞—Ç–µ–≥–æ—Ä–∏–π: {len(countries)}
- –î–∞—Ç–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {self.update_date}

---

*–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–∑ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–π Intermark Global*
"""
        
        index_path = self.knowledge_dir / "00_index.md"
        with open(index_path, 'w', encoding='utf-8') as f:
            f.write(index_content)
        
        self.log(f"‚úÖ –û–±–Ω–æ–≤–ª—ë–Ω –∏–Ω–¥–µ–∫—Å–Ω—ã–π —Ñ–∞–π–ª: 00_index.md")
    
    def create_update_log(self):
        """–°–æ–∑–¥–∞—Ç—å –ª–æ–≥ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è"""
        self.log("üìã –°–æ–∑–¥–∞–Ω–∏–µ –ª–æ–≥–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è...")
        
        log_content = f"""# –õ–æ–≥ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π

**–î–∞—Ç–∞:** {self.update_date}  
**–í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞:** {self.update_log[0].split(']')[0].strip('[')}  
**–í—Ä–µ–º—è –æ–∫–æ–Ω—á–∞–Ω–∏—è:** {self.update_log[-1].split(']')[0].strip('[')}

## –†–µ–∑—É–ª—å—Ç–∞—Ç—ã

- **–ù–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤:** {self.new_count}
- **–û–±–Ω–æ–≤–ª–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:** {self.updated_count}
- **–ë–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π:** {self.skipped_count}
- **–í—Å–µ–≥–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ:** {self.new_count + self.updated_count + self.skipped_count}

## –ü–æ–¥—Ä–æ–±–Ω—ã–π –ª–æ–≥

"""
        
        for entry in self.update_log:
            log_content += f"{entry}\n"
        
        log_path = self.knowledge_dir / "update_log.md"
        with open(log_path, 'w', encoding='utf-8') as f:
            f.write(log_content)
        
        self.log(f"‚úÖ –°–æ–∑–¥–∞–Ω –ª–æ–≥ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: update_log.md")
    
    def update(self):
        """–ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π"""
        self.log("üîÑ –ù–∞—á–∞–ª–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π")
        self.log(f"üìÇ –ò—Å—Ö–æ–¥–Ω–∞—è –ø–∞–ø–∫–∞: {self.raw_dir}")
        self.log(f"üìÇ –¶–µ–ª–µ–≤–∞—è –ø–∞–ø–∫–∞: {self.knowledge_dir}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏ knowledge
        if not self.knowledge_dir.exists():
            self.log("‚ö†Ô∏è  –ü–∞–ø–∫–∞ knowledge/ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞ /—Å–æ–∑–¥–∞—Ç—å_–±–∞–∑—É")
            self.log("   –°–æ–∑–¥–∞—é –Ω–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É...")
            self.knowledge_dir.mkdir(parents=True, exist_ok=True)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–∞–π–ª—ã
        countries = self.update_files()
        
        if not countries:
            self.log("‚ùå –ù–µ —Å–æ–∑–¥–∞–Ω–æ/–æ–±–Ω–æ–≤–ª–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞")
            return
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω–¥–µ–∫—Å
        self.create_index(countries)
        
        # –°–æ–∑–¥–∞–µ–º –ª–æ–≥
        self.create_update_log()
        
        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.log("")
        self.log("=" * 60)
        self.log(f"‚úÖ –ó–ê–í–ï–†–®–ï–ù–û")
        self.log(f"   –ù–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤: {self.new_count}")
        self.log(f"   –û–±–Ω–æ–≤–ª–µ–Ω–æ: {self.updated_count}")
        self.log(f"   –ë–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π: {self.skipped_count}")
        self.log(f"üìÖ –î–∞—Ç–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {self.update_date}")
        self.log("=" * 60)


def main():
    base_dir = Path(__file__).parent
    raw_dir = base_dir / "raw"
    knowledge_dir = base_dir / "knowledge"
    
    updater = KnowledgeBaseUpdater(raw_dir, knowledge_dir)
    updater.update()


if __name__ == "__main__":
    main()

