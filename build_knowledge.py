#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –∏–∑ PDF –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–π
–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–µ—Ç –ø–æ —Ç–µ–º–∞–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown
"""

import os
import sys
import hashlib
import re
import json
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
import shutil

try:
    import PyPDF2
except ImportError:
    print("–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫...")
    os.system(f"{sys.executable} -m pip install PyPDF2 --quiet")
    import PyPDF2

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
MAX_WORKERS = min(os.cpu_count() - 1 if os.cpu_count() else 1, 6)
BATCH_SIZE = 4


class KnowledgeBaseBuilder:
    def __init__(self, raw_dir: str, knowledge_dir: str):
        self.raw_dir = Path(raw_dir)
        self.knowledge_dir = Path(knowledge_dir)
        self.build_date = datetime.now().strftime("%Y-%m-%d")
        self.documents = []
        self.build_log = []
        
    def log(self, message: str):
        """–î–æ–±–∞–≤–∏—Ç—å –∑–∞–ø–∏—Å—å –≤ –ª–æ–≥"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        log_entry = f"[{timestamp}] {message}"
        self.build_log.append(log_entry)
        print(log_entry)
    
    def calculate_checksum(self, file_path: Path) -> Tuple[str, int, float]:
        """–í—ã—á–∏—Å–ª–∏—Ç—å SHA256 —Ö–µ—à —Ñ–∞–π–ª–∞ + —Ä–∞–∑–º–µ—Ä + mtime"""
        sha256 = hashlib.sha256()
        with open(file_path, 'rb') as f:
            for chunk in iter(lambda: f.read(8192), b""):
                sha256.update(chunk)
        stat = file_path.stat()
        return sha256.hexdigest()[:16], stat.st_size, stat.st_mtime
    
    def extract_text_from_pdf(self, pdf_path: Path) -> Tuple[str, int]:
        """–ò–∑–≤–ª–µ—á—å –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∏–∑ PDF —Ñ–∞–π–ª–∞"""
        text_content = []
        page_count = 0
        
        try:
            with open(pdf_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                page_count = len(pdf_reader.pages)
                
                for page_num, page in enumerate(pdf_reader.pages, 1):
                    page_text = page.extract_text()
                    if page_text.strip():
                        # –î–æ–±–∞–≤–ª—è–µ–º –º–∞—Ä–∫–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                        text_content.append(f"--- –°–ª–∞–π–¥ {page_num} ---")
                        text_content.append(page_text.strip())
                        text_content.append("")
                        
        except Exception as e:
            self.log(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ {pdf_path.name}: {e}")
            return "", 0
        
        return "\n".join(text_content), page_count
    
    def categorize_file(self, filename: str, content: str) -> Dict[str, any]:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É"""
        filename_lower = filename.lower()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç—Ä–∞–Ω—É/—Ä–µ–≥–∏–æ–Ω –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        # –§–æ—Ä–º–∞—Ç: "Intermark. <Country/Region> <Program Type> ENG.pdf"
        match = re.match(r'Intermark\.\s+(.+?)\s+(Residence|Citizenship|Passport|visa|RP|PR|Permit)', 
                        filename, re.IGNORECASE)
        
        if match:
            country = match.group(1).strip()
        else:
            # –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å —Å—Ç—Ä–∞–Ω—É –∏–∑ –Ω–∞—á–∞–ª–∞ –∏–º–µ–Ω–∏
            parts = filename.replace("Intermark.", "").replace("ENG.pdf", "").strip().split(".")
            country = parts[0].strip() if parts else "–û–±—â–µ–µ"
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø—Ä–æ–≥—Ä–∞–º–º—ã
        if any(word in filename_lower for word in ['citizenship', '–≥—Ä–∞–∂–¥–∞–Ω—Å—Ç–≤–æ']):
            program_type = '–ì—Ä–∞–∂–¥–∞–Ω—Å—Ç–≤–æ'
            subcategory = 'citizenship'
        elif any(word in filename_lower for word in ['permanent residence', 'pr']):
            program_type = '–ü–æ—Å—Ç–æ—è–Ω–Ω–æ–µ –ø—Ä–æ–∂–∏–≤–∞–Ω–∏–µ'
            subcategory = 'permanent-residence'
        elif any(word in filename_lower for word in ['residence permit', 'rp', 'visa']):
            program_type = '–í–∏–¥ –Ω–∞ –∂–∏—Ç–µ–ª—å—Å—Ç–≤–æ'
            subcategory = 'residence-permit'
        elif 'passport' in filename_lower:
            program_type = '–ü–∞—Å–ø–æ—Ä—Ç'
            subcategory = 'passport'
        elif 'golden visa' in filename_lower:
            program_type = '–ó–æ–ª–æ—Ç–∞—è –≤–∏–∑–∞'
            subcategory = 'golden-visa'
        else:
            program_type = '–û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è'
            subcategory = 'general'
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑ –ø–µ—Ä–≤—ã—Ö —Å—Ç—Ä–æ–∫ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        lines = [l.strip() for l in content.split('\n') if l.strip() and not l.startswith('---')]
        summary = ' '.join(lines[:3])[:200] if lines else "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∏–º–º–∏–≥—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º–µ"
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ–≥–∏
        tags = [country, program_type]
        if 'investment' in filename_lower or 'invest' in content.lower()[:500]:
            tags.append('–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏')
        if 'startup' in filename_lower:
            tags.append('—Å—Ç–∞—Ä—Ç–∞–ø')
        if 'digital nomad' in filename_lower:
            tags.append('digital-nomad')
        if 'financial independence' in filename_lower:
            tags.append('—Ñ–∏–Ω–∞–Ω—Å–æ–≤–∞—è-–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å')
        
        return {
            'country': country,
            'program_type': program_type,
            'subcategory': subcategory,
            'summary': summary,
            'tags': tags
        }
    
    def create_markdown_document(self, pdf_file: Path, text: str, page_count: int, 
                                 metadata: Dict) -> str:
        """–°–æ–∑–¥–∞—Ç—å Markdown –¥–æ–∫—É–º–µ–Ω—Ç –ø–æ —à–∞–±–ª–æ–Ω—É"""
        checksum = self.calculate_checksum(pdf_file)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è markdown
        safe_name = re.sub(r'[^\w\s-]', '', metadata['country'])
        safe_name = re.sub(r'[-\s]+', '-', safe_name).strip('-').lower()
        md_filename = f"{safe_name}-{metadata['subcategory']}.md"
        
        # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        doc = f"""---
title: "{metadata['country']}: {metadata['program_type']}"
summary: "{metadata['summary']}"
category: "{metadata['country']}"
subcategory: "{metadata['subcategory']}"
tags: {metadata['tags']}
source_files:
  - path: "raw/{pdf_file.name}"
    slides: [1-{page_count}]
extraction_date: "{self.build_date}"
version: "{checksum}"
checksum_sources: "{checksum}"
doc_type: "knowledge"
related: []
---

# {metadata['country']}: {metadata['program_type']}

## –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏

{text}

---

### –ò—Å—Ç–æ—á–Ω–∏–∫–∏
[^src1]: raw/{pdf_file.name} ‚Üí —Å–ª–∞–π–¥—ã 1‚Äì{page_count}
"""
        
        return md_filename, doc
    
    def clean_knowledge_dir(self):
        """–û—á–∏—Å—Ç–∏—Ç—å –ø–∞–ø–∫—É knowledge –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"""
        if self.knowledge_dir.exists():
            self.log(f"üóëÔ∏è  –û—á–∏—Å—Ç–∫–∞ –ø–∞–ø–∫–∏ {self.knowledge_dir}")
            shutil.rmtree(self.knowledge_dir)
        
        self.knowledge_dir.mkdir(parents=True, exist_ok=True)
        self.log(f"‚úÖ –°–æ–∑–¥–∞–Ω–∞ –ø–∞–ø–∫–∞ {self.knowledge_dir}")
    
    def process_single_file(self, pdf_file: Path, file_index: int, total_files: int) -> Tuple[Dict, str]:
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ–¥–∏–Ω PDF —Ñ–∞–π–ª (–¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è)"""
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
            text, page_count = self.extract_text_from_pdf(pdf_file)
            
            if not text:
                return None, f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—Å–∫ {pdf_file.name}: –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç"
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é
            metadata = self.categorize_file(pdf_file.name, text)
            
            # –°–æ–∑–¥–∞–µ–º markdown –¥–æ–∫—É–º–µ–Ω—Ç
            md_filename, md_content = self.create_markdown_document(
                pdf_file, text, page_count, metadata
            )
            
            # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Å—Ç—Ä–∞–Ω—ã –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            country_dir = self.knowledge_dir / metadata['country']
            country_dir.mkdir(exist_ok=True, parents=True)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã
            md_path = country_dir / md_filename
            version = 2
            while md_path.exists():
                base_name = md_filename.replace('.md', '')
                md_filename = f"{base_name}_v{version}.md"
                md_path = country_dir / md_filename
                version += 1
            
            with open(md_path, 'w', encoding='utf-8') as f:
                f.write(md_content)
            
            # –ì–æ—Ç–æ–≤–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ–∫—É–º–µ–Ω—Ç–µ
            doc_info = {
                'country': metadata['country'],
                'title': f"{metadata['country']}: {metadata['program_type']}",
                'path': f"{metadata['country']}/{md_filename}",
                'summary': metadata['summary'],
                'subcategory': metadata['subcategory'],
                'tags': metadata['tags'],
                'source_file': str(pdf_file.name),
                'checksum': self.calculate_checksum(pdf_file)[0]
            }
            
            return doc_info, f"‚úÖ –°–æ–∑–¥–∞–Ω: {metadata['country']}/{md_filename}"
            
        except Exception as e:
            return None, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {pdf_file.name}: {e}"
    
    def process_all_files(self):
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å–µ PDF —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ raw (—Å –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–æ–º)"""
        pdf_files = sorted(self.raw_dir.glob("*.pdf"))
        
        if not pdf_files:
            self.log("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ PDF —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ raw/")
            return
        
        self.log(f"üìö –ù–∞–π–¥–µ–Ω–æ {len(pdf_files)} PDF —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        self.log(f"‚ö° –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è {min(MAX_WORKERS, len(pdf_files))} –ø–æ—Ç–æ–∫–æ–≤")
        
        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Å—Ç—Ä–∞–Ω–∞–º
        countries = {}
        manifest_sources = []
        
        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤
        with ThreadPoolExecutor(max_workers=min(MAX_WORKERS, len(pdf_files))) as executor:
            futures = {}
            for i, pdf_file in enumerate(pdf_files):
                future = executor.submit(self.process_single_file, pdf_file, i + 1, len(pdf_files))
                futures[future] = pdf_file
            
            # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –º–µ—Ä–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏
            completed = 0
            for future in as_completed(futures):
                pdf_file = futures[future]
                completed += 1
                
                try:
                    doc_info, log_message = future.result()
                    
                    if doc_info:
                        self.documents.append(doc_info)
                        
                        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Å—Ç—Ä–∞–Ω–∞–º
                        country = doc_info['country']
                        if country not in countries:
                            countries[country] = []
                        countries[country].append(doc_info)
                        
                        # –î–æ–±–∞–≤–ª—è–µ–º –≤ manifest
                        checksum, size, mtime = self.calculate_checksum(pdf_file)
                        manifest_sources.append({
                            'path': f"raw/{pdf_file.name}",
                            'sha256': checksum,
                            'size': size,
                            'mtime': mtime
                        })
                    
                    # –õ–æ–≥–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–µ 10 —Ñ–∞–π–ª–æ–≤ –∏–ª–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π
                    if completed % 10 == 0 or completed == len(pdf_files):
                        self.log(f"üìÑ [{completed}/{len(pdf_files)}] {log_message}")
                    
                except Exception as e:
                    self.log(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {pdf_file.name}: {e}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º manifest
        self.save_manifest(manifest_sources)
        
        return countries
    
    def create_index(self, countries: Dict):
        """–°–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å–Ω—ã–π —Ñ–∞–π–ª 00_index.md"""
        self.log("üìë –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞...")
        
        index_content = f"""---
title: "–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π ‚Äî –ò–º–º–∏–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã"
type: "index"
created: "{self.build_date}"
total_documents: {len(self.documents)}
total_categories: {len(countries)}
version: "{hashlib.md5(str(self.documents).encode()).hexdigest()[:8]}"
---

# –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π ‚Äî –ò–º–º–∏–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã

–ü–æ–ª–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏–º–º–∏–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö –ø—Ä–æ–≥—Ä–∞–º–º Intermark Global.

**–û–±–Ω–æ–≤–ª–µ–Ω–æ:** {self.build_date}  
**–í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:** {len(self.documents)}  
**–ö–∞—Ç–µ–≥–æ—Ä–∏–π (—Å—Ç—Ä–∞–Ω/—Ä–µ–≥–∏–æ–Ω–æ–≤):** {len(countries)}

---

## –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ —Å—Ç—Ä–∞–Ω–∞–º

"""
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Å—Ç—Ä–∞–Ω—ã –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É
        for country in sorted(countries.keys()):
            docs = countries[country]
            index_content += f"\n### {country}\n\n"
            
            for doc in sorted(docs, key=lambda x: x['subcategory']):
                index_content += f"- [{doc['title']}]({doc['path']})\n"
                index_content += f"  - *{doc['summary'][:100]}...*\n"
        
        index_content += f"""

---

## –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞

- –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(self.documents)}
- –ö–∞—Ç–µ–≥–æ—Ä–∏–π: {len(countries)}
- –î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è: {self.build_date}

---

*–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–∑ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–π Intermark Global*
"""
        
        index_path = self.knowledge_dir / "00_index.md"
        with open(index_path, 'w', encoding='utf-8') as f:
            f.write(index_content)
        
        self.log(f"‚úÖ –°–æ–∑–¥–∞–Ω –∏–Ω–¥–µ–∫—Å–Ω—ã–π —Ñ–∞–π–ª: 00_index.md")
    
    def save_manifest(self, sources: List[Dict]):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å manifest.json"""
        try:
            manifest = {
                'version': f"build_{self.build_date}_{datetime.now().strftime('%H-%M')}",
                'created': datetime.now().isoformat(),
                'sources': sources,
                'total_documents': len(self.documents),
                'total_sources': len(sources)
            }
            
            manifest_path = self.knowledge_dir / 'manifest.json'
            with open(manifest_path, 'w', encoding='utf-8') as f:
                json.dump(manifest, f, indent=2, ensure_ascii=False)
            
            self.log(f"‚úÖ –°–æ–∑–¥–∞–Ω manifest: {len(sources)} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤")
        except Exception as e:
            self.log(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è manifest: {e}")
    
    def create_build_log(self):
        """–°–æ–∑–¥–∞—Ç—å –ª–æ–≥ —Å–±–æ—Ä–∫–∏"""
        self.log("üìã –°–æ–∑–¥–∞–Ω–∏–µ –ª–æ–≥–∞ —Å–±–æ—Ä–∫–∏...")
        
        log_content = f"""# –õ–æ–≥ —Å–±–æ—Ä–∫–∏ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π

**–î–∞—Ç–∞:** {self.build_date}  
**–í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞:** {self.build_log[0].split(']')[0].strip('[')}  
**–í—Ä–µ–º—è –æ–∫–æ–Ω—á–∞–Ω–∏—è:** {self.build_log[-1].split(']')[0].strip('[')}

## –†–µ–∑—É–ª—å—Ç–∞—Ç—ã

- **–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤:** {len(self.documents)}
- **–°–æ–∑–¥–∞–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:** {len(self.documents)}
- **–ö–∞—Ç–µ–≥–æ—Ä–∏–π:** {len(set(doc['country'] for doc in self.documents))}

## –ü–æ–¥—Ä–æ–±–Ω—ã–π –ª–æ–≥

"""
        
        for entry in self.build_log:
            log_content += f"{entry}\n"
        
        log_path = self.knowledge_dir / "build_log.md"
        with open(log_path, 'w', encoding='utf-8') as f:
            f.write(log_content)
        
        self.log(f"‚úÖ –°–æ–∑–¥–∞–Ω –ª–æ–≥ —Å–±–æ—Ä–∫–∏: build_log.md")
    
    def build(self):
        """–ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ —Å–±–æ—Ä–∫–∏ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π"""
        self.log("üöÄ –ù–∞—á–∞–ª–æ —Å–æ–∑–¥–∞–Ω–∏—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π")
        self.log(f"üìÇ –ò—Å—Ö–æ–¥–Ω–∞—è –ø–∞–ø–∫–∞: {self.raw_dir}")
        self.log(f"üìÇ –¶–µ–ª–µ–≤–∞—è –ø–∞–ø–∫–∞: {self.knowledge_dir}")
        
        # –®–∞–≥ 1: –û—á–∏—Å—Ç–∫–∞
        self.clean_knowledge_dir()
        
        # –®–∞–≥ 2: –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤
        countries = self.process_all_files()
        
        if not countries:
            self.log("‚ùå –ù–µ —Å–æ–∑–¥–∞–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞")
            return
        
        # –®–∞–≥ 3: –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞
        self.create_index(countries)
        
        # –®–∞–≥ 4: –°–æ–∑–¥–∞–Ω–∏–µ –ª–æ–≥–∞
        self.create_build_log()
        
        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.log("")
        self.log("=" * 60)
        self.log(f"‚úÖ –ó–ê–í–ï–†–®–ï–ù–û: –°–æ–∑–¥–∞–Ω–æ {len(self.documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ {len(list(self.raw_dir.glob('*.pdf')))} –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–π")
        self.log(f"üìä –ö–∞—Ç–µ–≥–æ—Ä–∏–π (—Å—Ç—Ä–∞–Ω): {len(countries)}")
        self.log(f"üìÖ –î–∞—Ç–∞ —Å–±–æ—Ä–∫–∏: {self.build_date}")
        self.log("=" * 60)


def main():
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç–∏
    base_dir = Path(__file__).parent
    raw_dir = base_dir / "raw"
    knowledge_dir = base_dir / "knowledge"
    
    # –°–æ–∑–¥–∞–µ–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º —Å–±–æ—Ä—â–∏–∫
    builder = KnowledgeBaseBuilder(raw_dir, knowledge_dir)
    builder.build()


if __name__ == "__main__":
    main()

